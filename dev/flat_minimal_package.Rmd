---
title: "Graphs of Australian weather station temperatures in summer and winter"
output: html_document
---

```{r libraries, eval=FALSE, include=FALSE, message=FALSE, warning=FALSE}
library('dplyr')
library('ggplot2')
library('httr')
library('lubridate')
library('padr')
library('readr')
library('rlang')
library('rvest')
library('stringr')
library('utils')
library('zoo')
```

```{r function-download_temperatures, eval=FALSE}
#' @title
#' Download and clean Australian temperature data
#' 
#' @description
#' `download_temperatures` downloads maximum and/or minimum daily temperatures
#' for Australian weather stations, cleans and reformats the data, and returns
#' the combined data.
#'
#' @details
#' Daily maximum and/or minimum data for all years for multiple Australian
#' weather stations can be downloaded from the
#' \href{http://www.bom.gov.au/climate/data/}{Climate Data Online section} of
#' the Australian Bureau of Meteorology website.
#' 
#' Any download links must resemble one of the default ones provided below:
#' * \href{http://www.bom.gov.au/jsp/ncc/cdio/weatherData/av?p_nccObsCode=122&p_display_type=dailyDataFile&p_startYear=&p_c=&p_stn_num=023000}{Adelaide (West Terrace / Ngayirdapira) daily maximum temperature}
#' * \href{http://www.bom.gov.au/jsp/ncc/cdio/weatherData/av?p_nccObsCode=123&p_display_type=dailyDataFile&p_startYear=&p_c=&p_stn_num=023000}{Adelaide (West Terrace / Ngayirdapira) daily minimum temperature}
#' * \href{http://www.bom.gov.au/jsp/ncc/cdio/weatherData/av?p_nccObsCode=122&p_display_type=dailyDataFile&p_startYear=&p_c=&p_stn_num=023034}{Adelaide Airport daily maximum temperature}
#' * \href{http://www.bom.gov.au/jsp/ncc/cdio/weatherData/av?p_nccObsCode=123&p_display_type=dailyDataFile&p_startYear=&p_c=&p_stn_num=023034}{Adelaide Airport daily minimum temperature}
#' 
#' The hyperlinks are the same except for the parts containing the:
#' * \strong{product code} (122 = maximum; 123 = minimum)
#' * \strong{station number} (a six-digit code)
#' 
#' @param URLs A character vector of one or more specified download links.
#' Default links are for Adelaide temperature data (see the details section)
#' 
#' @importFrom dplyr arrange bind_rows contains first last matches mutate n rename select slice
#' @importFrom httr GET http_error user_agent
#' @importFrom padr pad
#' @importFrom readr read_csv read_lines
#' @importFrom rlang .data :=
#' @importFrom rvest html_attr html_element read_html
#' @importFrom stringr str_detect str_extract str_replace str_to_title
#' @importFrom utils download.file unzip
#' 
#' @return The cleaned and combined temperature data
#' 
#' @seealso
#' to come
#' 
#' @examples
#' \dontrun{
#'    # Download Sydney data instead of default (Adelaide) data
#'    # Station: Sydney Airport AMO (number 066037)
#'    # Product: Daily maximum temperature
#'    URLpart1 <- "http://www.bom.gov.au/jsp/ncc/cdio/weatherData/av?p_nccObsCode="
#'    product <- "122"
#'    URLpart2 <- "&p_display_type=dailyDataFile&p_startYear=&p_c=&p_stn_num="
#'    station <- "066037"
#'    download_temperatures(URLs = paste0(URLpart1, product, URLpart2, station))
#' }
#' 
#' @export
download_temperatures <-
  function(URLs = c(
    "http://www.bom.gov.au/jsp/ncc/cdio/weatherData/av?p_nccObsCode=122&p_display_type=dailyDataFile&p_startYear=&p_c=&p_stn_num=023000",
    "http://www.bom.gov.au/jsp/ncc/cdio/weatherData/av?p_nccObsCode=123&p_display_type=dailyDataFile&p_startYear=&p_c=&p_stn_num=023000",
    "http://www.bom.gov.au/jsp/ncc/cdio/weatherData/av?p_nccObsCode=122&p_display_type=dailyDataFile&p_startYear=&p_c=&p_stn_num=023034",
    "http://www.bom.gov.au/jsp/ncc/cdio/weatherData/av?p_nccObsCode=123&p_display_type=dailyDataFile&p_startYear=&p_c=&p_stn_num=023034"
  )) {
    # Validate URLs argument
    stopifnot("The URL(s) are not valid" = !is.null(URLs))
    stopifnot("The URL(s) are not valid" = is.character(URLs) == TRUE)
    stopifnot("The URL(s) are not valid" = !all(unlist(lapply(URLs, http_error))) == TRUE)
    stopifnot("The URL(s) are not valid" = all(unlist(
      lapply(
        URLs,
        str_detect,
        "^\\Qhttp://www.bom.gov.au/jsp/ncc/cdio/weatherData/av?p_nccObsCode=\\E\\d{3}\\Q&p_display_type=dailyDataFile&p_startYear=&p_c=&p_stn_num=\\E\\d{6}$"
      )
    )) == TRUE)
    
    # Initialise raw datasets list
    raw_datasets <- list()
    
    # Extract downloaded datasets
    for (URL in URLs) {
      # Define user-agent and headers
      user_agent <-
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36"
      headers = c(`user-agent` = user_agent)
      
      # Extract download link
      download_link <- GET(URL, user_agent(user_agent)) |>
        read_html() |>
        html_element("#content-block > ul.downloads > li:nth-child(2) > a") |>
        html_attr('href') |>
        paste0('http://www.bom.gov.au', . = _)
      
      # Create temporary file to download zipped file in to
      temp_file <- tempfile(fileext = ".zip")
      
      # Create temporary directory to store zipped file in
      temp_dir <- tempfile()
      
      # Download zipped file
      download.file(
        download_link,
        temp_file,
        mode = "wb",
        headers = headers,
        quiet = TRUE
      )
      
      # Unzip downloaded file
      unzip(zipfile = temp_file, exdir = temp_dir)
      
      # Extract filenames
      data_file <- list.files(temp_dir, '*.csv')
      note_file <- list.files(temp_dir, '*.txt')
      
      # Extract dataset notes
      notes <-
        read_lines(paste(temp_dir, note_file, sep = '/'), skip_empty_rows = TRUE)
      
      # Extract location
      relevant_row_number <- grep('^Station name:', notes)
      relevant_row <- notes[relevant_row_number]
      location <-
        str_to_title(str_replace(relevant_row, 'Station name: ', ''))
      
      # Extract temperature type
      relevant_row_number <- grep('^Notes for Daily', notes)
      relevant_row <- notes[relevant_row_number]
      type <-
        str_extract(str_to_title(relevant_row), pattern = str_to_title(c("maximum|minimum")))
      
      # Extract raw dataset
      raw_dataset <-
        read_csv(
          file.path(temp_dir, data_file),
          col_select = c(.data$Year, .data$Month, .data$Day, contains('degree')),
          show_col_types = FALSE
        ) |>
        mutate(
          Month = as.numeric(.data$Month),
          Day = as.numeric(.data$Day),
          Location = location,
          Type = type
        ) |>
        rename("Temperature" := matches('(degree)'))
      
      # Insert rows for any missing dates
      raw_dataset <- raw_dataset |>
        mutate(Date = as.Date(paste(
          .data$Year, .data$Month, .data$Day, sep = '-'
        ))) |>
        pad(interval = 'day') |>
        select(
          .data$Year,
          .data$Month,
          .data$Day,
          .data$Location,
          .data$Type,
          .data$Temperature,
          -.data$Date
        )
      
      # Remove any starting or ending rows where all measurements are missing
      raw_dataset <- raw_dataset |>
        slice(first(which(!is.na(
          .data$Temperature
        ))):n()) |>
        slice(1:last(which(!is.na(
          .data$Temperature
        ))))
      
      # Merge datasets
      raw_datasets <- append(raw_datasets, list(raw_dataset))
    }
    
    # Combine datasets
    combined_dataset <- bind_rows(raw_datasets) |>
      arrange(.data$Year, .data$Month, .data$Day)
    
    # Return combined datasets
    return(combined_dataset)
  }
```